---
title: 'The genius of the Lagrangian'
date: 2026-02-05
permalink: /posts/2026/08/blog-post-1/
tags:
  - Microeconomics
  - Calculus
  - Optimization
---

I must admit that, after five and a half years of studying economics and statistics attentively, and after having used Lagrange multipliers in countless courses and situations, I barely knew why they were used or why they allow solving optimization problems.  
Obviously, being familiar with derivative-based optimization methods, I could intuit that differentiating a function that combined both the objective and the constraints could be useful to find a solution. Still, until very recently I wouldn’t have been able to explain why this works.

Everything changed when, while preparing for the master's program I will start this September, I read the optimization chapter in *Mathematics for Economists* (Simone & Blume). While doing the exercises I realized I didn’t understand why Lagrange multipliers were used. Driven by curiosity —and after spending longer on it than I’d like to admit— I finally understood it and was fascinated by the simplicity and power of the idea.

This post may not help many people, but for those economics students who struggle conceptually with the Lagrangian in nonlinear programming problems, here is a sketch of the logic behind the Lagrangian.

Given an optimization problem like the following:

maximize $f(x,y)$  
subject to $h(x,y) = c$

the conditions that must hold to find the solution are the following:

1. The constraint must be satisfied: beyond the final value, the solution must lie inside the space defined by the constraint set. Thus, we require $h(x,y)=c$.

2. The level curves of the objective function, at the optimal point, must be tangent to the curve defined by the constraint. To explain more clearly: level curves are those curves we obtain when we fix a value for $f(x,y)$. For example, if $f(x,y)=2x+y^2$, the level curve corresponding to the value 2 is $2=2x+y^2$. In an unconstrained problem we look for points where the gradient of the objective is zero (stationary points). But with a constraint we cannot move freely: we can only move along the curve $h(x,y)=c$. Therefore, the direction in which the solution can move (the tangent to the constraint) must, to first order, be a direction in which $f$ does not improve —this means the level curve of $f$ is tangent to the curve $h(x,y)=c$. When two curves are tangent, their normals (the gradient vectors) are parallel. Thus, for $(x,y)$ to be optimal subject to the constraint, it is necessary that  
$\nabla f(x,y) = \lambda \nabla h(x,y)$  
for some scalar $\lambda$. This $\lambda$ is the Lagrange multiplier: what matters is the proportionality between the gradients.

There are many methods to find points that satisfy these conditions (trial and error, iterative methods, derivative-based optimization, etc.), but typically one needs to verify the constraint and the gradient-parallel condition in separate steps.

The Lagrangian simplifies this. Instead of treating the two equations separately, we integrate them into a function of higher dimensionality and optimize a single function: the Lagrangian.

Define the Lagrangian as

$$
\mathcal{L}(x,y,\lambda) = f(x,y) - \lambda \,[\,h(x,y)-c\,].
$$

The first-order conditions —the partial derivatives of the Lagrangian set to zero— give us both properties at once. Let’s see how:

Differentiating with respect to $x$ and $y$ and setting to zero preserves the proportionality of the gradient components:

$$
\frac{\partial \mathcal{L}}{\partial x}
= \frac{\partial f}{\partial x}
- \lambda \frac{\partial h}{\partial x}
= 0
\quad\Rightarrow\quad
(\nabla f)_x = \lambda (\nabla h)_x,
$$

$$
\frac{\partial \mathcal{L}}{\partial y}
= \frac{\partial f}{\partial y}
- \lambda \frac{\partial h}{\partial y}
= 0
\quad\Rightarrow\quad
(\nabla f)_y = \lambda (\nabla h)_y.
$$

And differentiating with respect to $\lambda$ enforces the original constraint:

$$
\frac{\partial \mathcal{L}}{\partial \lambda}
= -(h(x,y)-c)
= 0
\quad\Rightarrow\quad
h(x,y)=c.
$$

Therefore, by condensing the problem into a single function, we obtain a system of equations (the three partial-derivative equations) that finds points satisfying both the constraint and the gradient-parallel condition simultaneously. Isn’t that an elegant idea?

I could go on about how interesting the multiplier $\lambda$ is: beyond seeming like an artificial addition, it measures the sensitivity of the optimal value to the constant $c$ in the constraint. In economic terms, $\lambda$ is often interpreted as the “shadow price,” i.e., the marginal value of a scarce resource. But maybe I’ll leave that for another post.
